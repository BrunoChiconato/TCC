# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQgpJ_68TAbUXNA9VuMCichJIPymp1Kd
"""

!pip install PyPDF2

import PyPDF2
import nltk
from nltk.corpus import stopwords
from collections import Counter
from google.colab import files

# Baixe os recursos do NLTK, se ainda não os tiver
nltk.download('stopwords')
nltk.download('punkt')

def extract_text_from_pdf(pdf_path):
    with open(pdf_path, 'rb') as file:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

def count_words(text):
    stop_words = set(stopwords.words('portuguese')) | {"sobre", "todos", "todas"}
    words = nltk.word_tokenize(text.lower())
    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]
    word_counts = Counter(filtered_words)
    return word_counts.most_common(10)

def find_cooccurring_words(text, top_words):
    stop_words = set(stopwords.words('portuguese')) | {"sobre", "todos", "todas"}
    words = nltk.word_tokenize(text.lower())
    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]

    cooccurrences = {word: Counter() for word in top_words}
    for i, word in enumerate(filtered_words):
        if word in top_words:
            context_window = filtered_words[max(0, i-5):min(len(filtered_words), i+6)]
            context_words = [w for w in context_window if w != word]
            cooccurrences[word].update(context_words)

    top_cooccurrences = {word: cooccurrences[word].most_common(5) for word in top_words}
    return top_cooccurrences

if __name__ == "__main__":
    print("Por favor, carregue o arquivo PDF.")
    uploaded = files.upload()
    pdf_path = next(iter(uploaded))  # Obtém o caminho do primeiro arquivo carregado

    if pdf_path:
        text = extract_text_from_pdf(pdf_path)
        most_common_words = count_words(text)
        top_10_words = [word for word, _ in most_common_words]

        top_cooccurrences = find_cooccurring_words(text, top_10_words)

        for word, count in most_common_words:
            print(f"Palavra: {word} - Ocorrências: {count}")
            print("Top 5 palavras que acompanham:")
            for co_word, co_count in top_cooccurrences[word]:
                print(f" - {co_word}: {co_count}")
    else:
        print("Nenhum arquivo carregado.")

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Dados fornecidos
data = {
    'Palavra': ['desenvolvimento', 'desenvolvimento', 'desenvolvimento', 'desenvolvimento', 'desenvolvimento',
                'países', 'países', 'países', 'países', 'países',
                'sustentável', 'sustentável', 'sustentável', 'sustentável', 'sustentável',
                'agenda', 'agenda', 'agenda', 'agenda', 'agenda',
                'incluindo', 'incluindo', 'incluindo', 'incluindo', 'incluindo',
                '2030', '2030', '2030', '2030', '2030',
                'global', 'global', 'global', 'global', 'global',
                'desenvolvidos', 'desenvolvidos', 'desenvolvidos', 'desenvolvidos', 'desenvolvidos',
                'menos', 'menos', 'menos', 'menos', 'menos',
                'nacionais', 'nacionais', 'nacionais', 'nacionais', 'nacionais'],
    'Acompanha': ['países', 'sustentável', 'pequenos', 'desenvolvidos', 'estados',
                  'desenvolvimento', 'desenvolvidos', 'menos', 'pequenos', 'estados',
                  'desenvolvimento', 'promover', 'objetivos', 'países', 'recursos',
                  'desenvolvimento', 'ação', 'implementação', 'nova', 'objetivos',
                  'desenvolvimento', 'países', 'sustentável', 'pobreza', 'formas',
                  'acesso', 'reduzir', 'garantir', 'sustentável', 'desenvolvimento',
                  'desenvolvimento', 'sustentável', 'parceria', 'nível', 'implementação',
                  'países', 'menos', 'desenvolvimento', 'estados', 'pequenos',
                  'países', 'desenvolvidos', 'desenvolvimento', 'pequenos', 'estados',
                  'desenvolvimento', 'políticas', 'prioridades', 'níveis', 'acordo'],
    'Frequência': [146, 117, 42, 39, 37,
                   146, 93, 75, 33, 32,
                   117, 21, 20, 18, 17,
                   23, 18, 17, 16, 15,
                   21, 18, 7, 6, 6,
                   13, 11, 11, 10, 9,
                   16, 14, 13, 11, 11,
                   93, 43, 39, 21, 19,
                   75, 43, 36, 20, 12,
                   20, 14, 10, 9, 9]
}

# Criação do DataFrame
df = pd.DataFrame(data)

# Configuração do gráfico
plt.figure(figsize=(10, 15))
sns.set(style="whitegrid")
sns.barplot(x="Frequência", y="Acompanha", hue="Palavra", data=df, palette="tab10")

# Ajustes de estilo e títulos
plt.title("Frequência das Palavras que Acompanham as Top 10 Palavras Mais Comuns")
plt.xlabel("Frequência")
plt.ylabel("Palavras que Acompanham")
plt.legend(title="Top 10 Palavras", bbox_to_anchor=(1.05, 1), loc='upper left')

# Exibição do gráfico
plt.tight_layout()
plt.show()